# ###########################################################################
#
# DIESES SKRIPT IST UNSERE "KISS-HYBRID" PROJEKT-LOGIK
#
# VERSION 2: Inklusive CSV-Export für Merkmals-Analyse
#
# ###########################################################################

import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Tuple, Any
import os
import shutil # Wird für das Erstellen/Löschen von Ordnern benötigt

# Notwendig, für die finale Auswertung (Accuracy, Report).
from sklearn.metrics import accuracy_score, classification_report


# ###########################################################################
# TEIL 1: (ENTFERNT)
# ###########################################################################
# (Keine "magischen" Listen)


# ###########################################################################
# TEIL 2: UNSER "KISS"-KLASSIFIKATOR
# ###########################################################################

# Wir definieren die Klassen, die wir am Ende für den Report brauchen.
CLASSES = ['Bruch', 'Farbfehler', 'Normal', 'Rest']

def kiss_classifier(features: Dict[str, float]) -> str:
    """
    Unser eigenes, super-simples Regel-System (KISS-Prinzip).
    
    HINWEIS: Die Schwellenwerte hier sind die, die zu 78% geführt haben.
    Wir werden sie ANPASSEN, nachdem wir die feature_analysis.csv
    ausgewertet haben.
    """

    # --- REGEL 1: BRUCH ---
    # Annahme: Alles unter 98% Solidität ist ein Bruch.
    # (Diese Regel ist laut Diagnose zu schwach)
    if features["solidity"] < 0.98:
        return "Bruch"

    # --- REGEL 2: FARBFEHLER ---
    # Annahme: Normale Objekte haben einen hohen Gelb-Wert (z.B. > 130).
    # (Diese Regel ist laut Diagnose KOMPLETT FALSCH)
    if features["b_mean"] < 130.0:
        return "Farbfehler"
        
    # --- REGEL 3: REST ---
    # Annahme: Alles unter 92% Symmetrie ist "Rest".
    # (Diese Regel ist laut Diagnose zu aggressiv)
    if features["symmetry"] < 0.92:
        return "Rest"

    # --- REGEL 4: NORMAL ---
    return "Normal"


# ###########################################################################
# TEIL 3: HINTERGRUND-ENTFERNUNG (Aus Phillips Code, 1:1 übernommen)
# ###########################################################################

@dataclass
class SegmentationResult:
    mask: np.ndarray
    cropped_image: np.ndarray
    cropped_mask: np.ndarray
    bbox: Tuple[int, int, int, int]
    area_ratio: float
    raw_mask: np.ndarray
    blurred: np.ndarray

class BackgroundSegmenter:
    """
    Entfernt den Hintergrund. Dies ist die "klassische Bildverarbeitung".
    Perfekt erklärbar für die Prüfung.
    """
    def __init__(self) -> None:
        self.blur_size = 5
        self.median_kernel_size = 5
        self.morph_iterations = 1
        self.close_then_open = True
        self.keep_largest_object = True
        self.invert_threshold = 200
        self.kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))

    def segment(self, image: np.ndarray) -> SegmentationResult:
        blurred = cv2.GaussianBlur(image, (self.blur_size, self.blur_size), 0)
        lab = cv2.cvtColor(blurred, cv2.COLOR_BGR2LAB)
        lightness = lab[:, :, 0]
        _, mask = cv2.threshold(lightness, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        if mask.mean() > self.invert_threshold:
            mask = 255 - mask
            
        raw_mask = mask.copy()
        mask = cv2.medianBlur(mask, self.median_kernel_size)
        
        operations = (cv2.MORPH_CLOSE, cv2.MORPH_OPEN)
        for op in operations:
            mask = cv2.morphologyEx(mask, op, self.kernel, iterations=self.morph_iterations)
            
        cleaned = self._keep_largest_object(mask)
        
        h, w = cleaned.shape
        area_ratio = float(cleaned.sum() / 255) / (h * w)
        
        y0, y1, x0, x1 = self._bounding_box(cleaned)
        if x1 - x0 <= 1 or y1 - y0 <= 1:
            x0, y0, x1, y1 = 0, 0, w, h
            
        cropped_mask = cleaned[y0:y1, x0:x1]
        cropped_image = image[y0:y1, x0:x1].copy()
        foreground = cv2.bitwise_and(cropped_image, cropped_image, mask=cropped_mask)
        
        return SegmentationResult(
            mask=cleaned,
            cropped_image=foreground,
            cropped_mask=cropped_mask,
            bbox=(x0, y0, x1, y1),
            area_ratio=area_ratio,
            raw_mask=raw_mask,
            blurred=blurred,
        )

    @staticmethod
    def _keep_largest_object(mask: np.ndarray) -> np.ndarray:
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not cnts:
            return np.zeros_like(mask)
        largest = max(cnts, key=cv2.contourArea)
        cleaned = np.zeros_like(mask)
        cv2.drawContours(cleaned, [largest], -1, 255, -1)
        return cleaned

    @staticmethod
    def _bounding_box(mask: np.ndarray) -> Tuple[int, int, int, int]:
        coords = np.column_stack(np.nonzero(mask))
        if coords.size == 0:
            return (0, 0, mask.shape[1], mask.shape[0])
        ys, xs = coords[:, 0], coords[:, 1]
        return (xs.min(), ys.min(), xs.max() + 1, ys.max() + 1)


# ###########################################################################
# TEIL 4: MERKMALS-EXTRAKTION (Aus Phillips Code, 1:1 übernommen)
# ###########################################################################

def _symmetry_score(mask: np.ndarray) -> float:
    h, w = mask.shape
    if w == 0 or h == 0: return 0.0
    mid = w // 2
    left = mask[:, :mid]
    right = mask[:, mid:]
    right = np.fliplr(right)
    min_w = min(left.shape[1], right.shape[1])
    if min_w == 0: return 0.0
    diff = np.abs(left[:, :min_w] - right[:, :min_w]).sum() / 255.0
    content = mask.sum() / 255.0
    if content == 0: return 0.0
    score = 1.0 - (diff / content)
    return max(0.0, min(1.0, score))

def extract_features(image: np.ndarray, segmentation: SegmentationResult) -> Dict[str, float]:
    mask = segmentation.mask
    if mask.sum() == 0:
        raise ValueError("Segmentierungsmaske ist leer.")

    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnt = max(cnts, key=cv2.contourArea)
    area = cv2.contourArea(cnt)
    perimeter = cv2.arcLength(cnt, True)
    hull = cv2.convexHull(cnt)
    hull_area = cv2.contourArea(hull)
    hull_perimeter = cv2.arcLength(hull, True)
    h, w = mask.shape
    x0, y0, x1, y1 = segmentation.bbox
    bbox_area = max(1, (x1 - x0) * (y1 - y0))
    
    cropped_mask = segmentation.cropped_mask
    symmetry = _symmetry_score(cropped_mask)
    
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    masked_pixels = lab[mask == 255]
    L = masked_pixels[:, 0]
    a = masked_pixels[:, 1]
    b = masked_pixels[:, 2]
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    laplacian = cv2.Laplacian(gray, cv2.CV_64F, ksize=1)
    laplacian_std = float(np.std(laplacian[mask == 255]))

    features = {
        "area_ratio": float(area / (h * w)),
        "bbox_ratio": float(area / bbox_area),
        "solidity": float(area / hull_area) if hull_area else 0.0,
        "elongation": float((x1 - x0) / ((y1 - y0) + 1e-6)),
        "perimeter_ratio": float(perimeter / (2 * (h + w))),
        "roughness": float(hull_perimeter / (perimeter + 1e-6)),
        "symmetry": float(symmetry),
        "lightness_mean": float(L.mean()),
        "lightness_std": float(L.std()),
        "a_mean": float(a.mean()),
        "a_std": float(a.std()),
        "b_mean": float(b.mean()),
        "b_std": float(b.std()),
        "dark_fraction": float((L < 170).mean()),
        "bright_fraction": float((L > 210).mean()),
        "yellow_fraction": float((b > 150).mean()),
        "red_fraction": float((a > 150).mean()),
        "laplacian_std": laplacian_std,
    }
    return features


# ###########################################################################
# TEIL 5: KONFIGURATION & DATENLADEN (Aus Phillips Code, 1:1 übernommen)
# ###########################################################################

BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
NORMAL_DIR = DATA_DIR / "Images" / "Normal"
ANOMALY_DIR = DATA_DIR / "Images" / "Anomaly"
ANNOTATION_FILE = DATA_DIR / "image_anno.csv"
TARGET_CLASSES = tuple(CLASSES)

AGGREGATED_CLASS_MAPPING = {
    "normal": "Normal", "burnt": "Farbfehler", "different colour spot": "Farbfehler",
    "different colour spot,similar colour spot": "Farbfehler", "similar colour spot": "Farbfehler",
    "similar colour spot,other": "Farbfehler", "similar colour spot,small scratches": "Farbfehler",
    "small scratches": "Farbfehler", "corner or edge breakage": "Bruch",
    "corner or edge breakage,small scratches": "Bruch", "middle breakage": "Bruch",
    "middle breakage,small scratches": "Bruch", "middle breakage,similar colour spot": "Bruch",
    "fryum stuck together": "Rest",
}

OUTPUT_ROOT = BASE_DIR / "output"
RUN_IMAGE_DIR = OUTPUT_ROOT / "classified"
MISCLASSIFIED_DIR = RUN_IMAGE_DIR / "Falsch"
TARGET_CLASS_DIRS = {cls: RUN_IMAGE_DIR / cls for cls in TARGET_CLASSES}

@dataclass(frozen=True)
class ImageRecord:
    relative_path: Path
    image_path: Path
    original_label: str
    target_label: str

def load_dataset() -> List[ImageRecord]:
    if not ANNOTATION_FILE.exists():
        raise FileNotFoundError(f"FEHLER: 'image_anno.csv' nicht gefunden unter: {ANNOTATION_FILE}")
    annotations = pd.read_csv(ANNOTATION_FILE)
    records: List[ImageRecord] = []
    for _, row in annotations.iterrows():
        rel_path = Path(row["image"])
        local_name = rel_path.name
        sub_dir = NORMAL_DIR if "Normal" in row["image"] else ANOMALY_DIR
        image_path = sub_dir / local_name
        original_label = str(row["label"]).strip()
        try:
            target_label = AGGREGATED_CLASS_MAPPING[original_label]
        except KeyError:
            continue
        records.append(ImageRecord(rel_path, image_path, original_label, target_label))
    return records

# ###########################################################################
# TEIL 5.5: DATEI-SPEICHERUNG (Aus Phillips Code, 1:1 übernommen)
# ###########################################################################

def _prefixed_name(filename: str, prediction: str, symmetry: float) -> str:
    path = Path(filename)
    if prediction != "Normal":
        return path.name
    scaled = max(0, min(999, int(round(symmetry * 1000))))
    prefix = f"SYM{scaled:03d}"
    return f"{prefix}_{path.name}"

def save_result(filename: str, prediction: str, target: str, cropped_image: np.ndarray, symmetry: float):
    predicted_dir = TARGET_CLASS_DIRS[prediction]
    prefixed_name = _prefixed_name(filename, prediction, symmetry)
    out_path = predicted_dir / prefixed_name
    cv2.imwrite(str(out_path), cropped_image)
    
    if prediction != target:
        stem = Path(filename).stem
        suffix = Path(filename).suffix
        mismatch_name = f"{stem}__gt-{target}_pred-{prediction}{suffix}"
        mismatch_path = MISCLASSIFIED_DIR / mismatch_name
        cv2.imwrite(str(mismatch_path), cropped_image)

def _setup_output_dirs():
    if RUN_IMAGE_DIR.exists():
        print(f"Lösche alten Ausgabeordner: {RUN_IMAGE_DIR}")
        shutil.rmtree(RUN_IMAGE_DIR)
    print(f"Erstelle Ausgabeordner unter: {RUN_IMAGE_DIR}")
    RUN_IMAGE_DIR.mkdir(parents=True, exist_ok=True)
    MISCLASSIFIED_DIR.mkdir(parents=True, exist_ok=True)
    for d in TARGET_CLASS_DIRS.values():
        d.mkdir(parents=True, exist_ok=True)


# ###########################################################################
# TEIL 6: DER HAUPTABLAUF (MAIN) - JETZT MIT CSV-EXPORT
# ###########################################################################

def run_classification_pipeline():
    print("Starte 'KISS-Hybrid' Klassifikations-Pipeline (v2 mit Analyse-Export)...")
    _setup_output_dirs()

    try:
        records = load_dataset()
        print(f"Schritt 1: Datensatz mit {len(records)} Bildern geladen.")
    except FileNotFoundError as e:
        print(e)
        return

    segmenter = BackgroundSegmenter()
    print("Schritt 2: Segmentierer initialisiert.")

    ground_truth = []
    predictions = []
    
    # *** NEU (1/3): Liste für unsere Analyse-Daten ***
    feature_data_for_analysis = []

    print(f"Schritt 3-5: Verarbeite, Klassifiziere & Speichere {len(records)} Bilder...")
    
    for i, record in enumerate(records):
        image = cv2.imread(str(record.image_path))
        if image is None:
            print(f"  Warnung: Bild {record.image_path.name} nicht gefunden. Übersprungen.")
            continue
            
        try:
            segmentation = segmenter.segment(image)
        except Exception as e:
            print(f"  Fehler bei Segmentierung von {record.image_path.name}: {e}. Übersprungen.")
            continue
        
        try:
            features = extract_features(image, segmentation)
        except ValueError as e:
            print(f"  Fehler bei Merkmals-Extraktion von {record.image_path.name}: {e}. Übersprungen.")
            continue
        
        predicted_label = kiss_classifier(features)
        true_label = record.target_label
        
        ground_truth.append(true_label)
        predictions.append(predicted_label)
        
        # *** NEU (2/3): Daten für Analyse-CSV sammeln ***
        analysis_row = features.copy() # Nimm alle 18 Merkmale
        analysis_row["TRUE_LABEL"] = true_label # Füge das wahre Label hinzu
        analysis_row["FILENAME"] = record.image_path.name # Dateiname für Referenz
        feature_data_for_analysis.append(analysis_row)
        
        # --- Speichern (unverändert) ---
        symmetry_score = features["symmetry"]
        cropped_image = segmentation.cropped_image
        filename = record.image_path.name
        save_result(filename, predicted_label, true_label, cropped_image, symmetry_score)
        
        # Logging (unverändert)
        if true_label != predicted_label:
            pass # Wir loggen nicht mehr jeden Fehler, wird zu voll
        
        if (i+1) % 50 == 0:
            print(f"  ... {i+1} / {len(records)} verarbeitet.")

    print("Schritt 3-5: Verarbeitung abgeschlossen.")
    
    # *** NEU (3/3): Analyse-Daten als CSV speichern ***
    print("\n--- MERKMALS-ANALYSE ---")
    try:
        analysis_df = pd.DataFrame(feature_data_for_analysis)
        analysis_path = OUTPUT_ROOT / "feature_analysis.csv"
        # Wir nutzen Semikolon, da Excel das in Deutschland lieber mag
        analysis_df.to_csv(analysis_path, index=False, sep=";")
        print(f"Analyse-Daten (feature_analysis.csv) erfolgreich in {OUTPUT_ROOT} gespeichert.")
    except Exception as e:
        print(f"FEHLER beim Speichern der Analyse-CSV: {e}")
    print("-------------------------------------------------\n")

    # --- FINALES ERGEBNIS (unverändert) ---
    print("-------------------------------------------------")
    accuracy = accuracy_score(ground_truth, predictions)
    print(f"Genauigkeit: {accuracy * 100:.2f}%")
    print("-------------------------------------------------")
    print("Classification Report (Präzision, Recall, F1):")
    # zero_division=0.0 setzt den Warning von sklearn außer Kraft
    print(classification_report(ground_truth, predictions, labels=list(TARGET_CLASSES), zero_division=0.0))
    print("-------------------------------------------------")
    print(f"Alle Bilder wurden in den Ordner '{RUN_IMAGE_DIR}' sortiert.")
    print("Pipeline erfolgreich beendet.")


if __name__ == "__main__":
    run_classification_pipeline()